import streamlit as st
import pandas as pd
import io
import chardet

st.set_page_config(page_title="ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿åˆ†å‰²ãƒ„ãƒ¼ãƒ«", layout="wide")

st.title("ğŸ“Š ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã€Œ;ã€åˆ†å‰²ãƒ„ãƒ¼ãƒ«")
st.markdown("""
ã“ã®ãƒ„ãƒ¼ãƒ«ã¯ã€ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆèª¿æŸ»çµæœã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã€ã€Œ;ã€ã§åŒºåˆ‡ã‚‰ã‚ŒãŸè¤‡æ•°å›ç­”ã‚»ãƒ«ã‚’æ¤œå‡ºã—ã€
é¸æŠè‚¢ã”ã¨ã«åˆ¥åˆ—ã«åˆ†å‰²ã—ã¾ã™ã€‚æ–‡å­—ã‚³ãƒ¼ãƒ‰ã¯è‡ªå‹•åˆ¤å®šã—ã¾ã™ã€‚
""")

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_file = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=['csv'])

if uploaded_file is not None:
    # æ–‡å­—ã‚³ãƒ¼ãƒ‰ã‚’è‡ªå‹•åˆ¤å®šã—ã¦èª­ã¿è¾¼ã¿
    try:
        raw_data = uploaded_file.read()
        detected = chardet.detect(raw_data)
        encoding = detected['encoding'] or 'cp932'
        st.info(f"ğŸ” æ–‡å­—ã‚³ãƒ¼ãƒ‰è‡ªå‹•åˆ¤å®š: {encoding}ï¼ˆä¿¡é ¼åº¦: {detected['confidence']:.0%}ï¼‰")
        df = pd.read_csv(io.BytesIO(raw_data), encoding=encoding)
        st.success(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {df.shape[0]}è¡Œ Ã— {df.shape[1]}åˆ—")
    except Exception as e:
        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        st.stop()

    # å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
    with st.expander("ğŸ“„ å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º", expanded=False):
        st.dataframe(df, use_container_width=True)

    # å‡¦ç†ãƒœã‚¿ãƒ³
    if st.button("ğŸ”„ ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã™ã‚‹", type="primary"):
        with st.spinner("å‡¦ç†ä¸­..."):
            split_info = []
            df_processed = df.copy()
            insert_plan = []  # (å…ƒåˆ—å, è¿½åŠ åˆ—åãƒªã‚¹ãƒˆ, col_data)

            for col in df.columns:
                # æœ€å¤§åˆ†å‰²æ•°ã‚’ç¢ºèª
                max_parts = 1
                for value in df[col]:
                    if pd.isna(value):
                        continue
                    value_str = str(value)
                    if ';' in value_str:
                        n = len(value_str.split(';'))
                        if n > max_parts:
                            max_parts = n

                if max_parts <= 1:
                    continue  # ã“ã®åˆ—ã«ã¯ã€Œ;ã€ãªã—

                # è¿½åŠ åˆ—ã®åå‰ã‚’ç”Ÿæˆï¼ˆä¾‹: Q1_1, Q1_2, ...ï¼‰
                new_col_names = [f"{col}_{i+1}" for i in range(max_parts)]
                col_data = {name: [None] * len(df) for name in new_col_names}

                for idx, value in enumerate(df[col]):
                    if pd.isna(value):
                        continue
                    value_str = str(value)
                    if ';' not in value_str:
                        col_data[new_col_names[0]][idx] = value_str.strip()
                        continue

                    parts = [p.strip() for p in value_str.split(';')]
                    for i, part in enumerate(parts):
                        col_data[new_col_names[i]][idx] = part

                    split_info.append({
                        'è¡Œ': idx + 2,
                        'åˆ—': col,
                        'å…ƒã®å€¤': value_str[:80] + '...' if len(value_str) > 80 else value_str,
                        'åˆ†å‰²æ•°': len(parts),
                    })

                insert_plan.append((col, new_col_names, col_data))

            # å…ƒã®åˆ—ã®å³éš£ã«é †ç•ªã«æŒ¿å…¥
            for col, new_col_names, col_data in insert_plan:
                base_idx = df_processed.columns.get_loc(col)
                for offset, new_col_name in enumerate(new_col_names):
                    df_processed.insert(base_idx + 1 + offset, new_col_name, col_data[new_col_name])

        # å‡¦ç†çµæœã‚’è¡¨ç¤º
        st.success(f"âœ… å‡¦ç†å®Œäº†: {len(split_info)}ä»¶ã®ã‚»ãƒ«ã‚’åˆ†å‰²ã—ã¾ã—ãŸ")

        if split_info:
            with st.expander(f"ğŸ” åˆ†å‰²ã•ã‚ŒãŸã‚»ãƒ«ã®è©³ç´° ({len(split_info)}ä»¶)", expanded=True):
                split_df = pd.DataFrame(split_info)
                st.dataframe(split_df, use_container_width=True)
        else:
            st.info("â„¹ï¸ ã€Œ;ã€åŒºåˆ‡ã‚Šã®ã‚»ãƒ«ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

        with st.expander("ğŸ“„ å‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º", expanded=True):
            st.dataframe(df_processed, use_container_width=True)

        st.markdown("---")
        col1, col2 = st.columns(2)

        with col1:
            csv_buffer = io.StringIO()
            df_processed.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
            csv_data = csv_buffer.getvalue().encode('utf-8-sig')
            st.download_button(
                label="ğŸ“¥ å‡¦ç†æ¸ˆã¿CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=csv_data,
                file_name="processed_data.csv",
                mime="text/csv",
                type="primary"
            )

        with col2:
            if split_info:
                split_csv_buffer = io.StringIO()
                split_df.to_csv(split_csv_buffer, index=False, encoding='utf-8-sig')
                split_csv_data = split_csv_buffer.getvalue().encode('utf-8-sig')
                st.download_button(
                    label="ğŸ“¥ åˆ†å‰²æƒ…å ±CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=split_csv_data,
                    file_name="split_info.csv",
                    mime="text/csv"
                )

else:
    st.info("ğŸ‘† CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")

    with st.expander("ğŸ“– ä½¿ã„æ–¹"):
        st.markdown("""
        ### å‡¦ç†å†…å®¹

        1. **æ–‡å­—ã‚³ãƒ¼ãƒ‰è‡ªå‹•åˆ¤å®š**: UTF-8 / Shift-JIS ãªã©ã‚’è‡ªå‹•æ¤œå‡ºã—ã¦èª­ã¿è¾¼ã¿ã¾ã™
        2. **ã‚»ãƒ«ã®æ¤œå‡º**: ã€Œ;ã€ã‚’å«ã‚€ã‚»ãƒ«ã‚’ã™ã¹ã¦å¯¾è±¡ã«ã—ã¾ã™
        3. **åˆ†å‰²å‡¦ç†**: ã€Œ;ã€ã§åˆ†å‰²ã—ã€é¸æŠè‚¢ã”ã¨ã«åˆ¥åˆ—ï¼ˆåˆ—å_1, åˆ—å_2, ...ï¼‰ã‚’ç”Ÿæˆ
        4. **æ–°ã—ã„åˆ—**: å…ƒã®åˆ—ã®å³éš£ã«é †ç•ªã«æŒ¿å…¥

        ### ä½¿ç”¨ä¾‹

        **å…ƒã®ãƒ‡ãƒ¼ã‚¿ï¼ˆ387:checkbox åˆ—ï¼‰:**
        ```
        ï¼‘ï¼Nombres de edificios;ï¼•ï¼Cuestionario de consulta
        ```

        **å‡¦ç†å¾Œ:**
        ```
        387:checkbox_1 åˆ—: "ï¼‘ï¼Nombres de edificios"
        387:checkbox_2 åˆ—: "ï¼•ï¼Cuestionario de consulta"
        ```
        """)
